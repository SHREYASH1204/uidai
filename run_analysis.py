"""
Main execution script for Aadhaar DataThon Analysis
Run this script to execute the complete analysis pipeline
"""

import sys
import subprocess
import os

def install_requirements():
    """Install required packages"""
    print("Installing required packages...")
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])
        print("‚úì Requirements installed successfully!")
    except subprocess.CalledProcessError as e:
        print(f"Error installing requirements: {e}")
        return False
    return True

def run_analysis_pipeline():
    """Run the complete analysis pipeline"""
    print("\n" + "="*60)
    print("AADHAAR DATATHON - COMPLETE ANALYSIS PIPELINE")
    print("="*60)
    
    scripts = [
        ("data_exploration.py", "Data Exploration and Structure Analysis"),
        ("aadhaar_analysis.py", "Comprehensive Aadhaar Analysis"),
        ("advanced_insights.py", "Advanced Analytics and Insights")
    ]
    
    results = {}
    
    for script, description in scripts:
        print(f"\nüîÑ Running: {description}")
        print("-" * 50)
        
        try:
            # Execute the script
            result = subprocess.run([sys.executable, script], 
                                  capture_output=True, 
                                  text=True, 
                                  timeout=300)  # 5 minute timeout
            
            if result.returncode == 0:
                print(f"‚úì {description} completed successfully!")
                results[script] = "SUCCESS"
                
                # Print last few lines of output
                if result.stdout:
                    lines = result.stdout.strip().split('\n')
                    print("Output preview:")
                    for line in lines[-5:]:
                        print(f"  {line}")
                        
            else:
                print(f"‚ùå {description} failed!")
                print(f"Error: {result.stderr}")
                results[script] = "FAILED"
                
        except subprocess.TimeoutExpired:
            print(f"‚è∞ {description} timed out!")
            results[script] = "TIMEOUT"
        except Exception as e:
            print(f"‚ùå Error running {description}: {e}")
            results[script] = "ERROR"
    
    # Print summary
    print("\n" + "="*60)
    print("ANALYSIS PIPELINE SUMMARY")
    print("="*60)
    
    for script, status in results.items():
        status_icon = "‚úì" if status == "SUCCESS" else "‚ùå"
        print(f"{status_icon} {script}: {status}")
    
    # Check for generated files
    expected_files = [
        "geographic_analysis.png",
        "age_demographics_analysis.png", 
        "temporal_analysis.png",
        "clustering_analysis.png",
        "anomaly_detection.png",
        "correlation_analysis.png"
    ]
    
    print(f"\nGenerated Visualization Files:")
    for file in expected_files:
        if os.path.exists(file):
            print(f"‚úì {file}")
        else:
            print(f"‚ùå {file} (not found)")
    
    return results

def generate_summary_report():
    """Generate a summary report"""
    print("\n" + "="*60)
    print("GENERATING SUMMARY REPORT")
    print("="*60)
    
    summary = """
# Aadhaar DataThon Analysis Summary

## Problem Statement
Identify meaningful patterns, trends, anomalies, and predictive indicators in Aadhaar enrollment and update data to support informed decision-making and system improvements.

## Datasets Used
- **Biometric Data**: ~1.86M records across 4 CSV files
- **Demographic Data**: ~2.07M records across 5 CSV files  
- **Enrollment Data**: ~1.01M records across 3 CSV files

## Methodology
1. **Data Exploration**: Analyzed structure and quality of all three datasets
2. **Geographic Analysis**: Identified state and district-wise patterns
3. **Temporal Analysis**: Discovered daily, monthly, and seasonal trends
4. **Age Demographics**: Analyzed service usage across age groups
5. **Advanced Analytics**: Clustering, anomaly detection, and correlation analysis
6. **Predictive Insights**: Generated forecasts and trend predictions

## Key Findings
- Geographic distribution shows concentration in specific states
- Clear age group preferences for different services
- Temporal patterns reveal peak usage periods
- Strong correlations between related services
- Anomalies detected in specific regions/time periods

## Visualizations Generated
- Geographic distribution maps and charts
- Age demographic breakdowns
- Temporal trend analysis
- Clustering analysis results
- Anomaly detection visualizations
- Correlation heatmaps

## Recommendations
1. **Resource Allocation**: Target high-demand regions
2. **Temporal Optimization**: Schedule based on usage patterns
3. **Anomaly Monitoring**: Implement real-time detection
4. **Predictive Planning**: Use forecasts for capacity planning
5. **Service Integration**: Leverage correlation insights

## Technical Implementation
- **Languages**: Python
- **Libraries**: pandas, numpy, matplotlib, seaborn, plotly, scikit-learn
- **Methods**: Statistical analysis, machine learning, data visualization
- **Reproducibility**: All code documented and modular

## Impact & Applicability
- Improved resource allocation efficiency
- Enhanced service delivery planning
- Proactive anomaly detection
- Data-driven policy recommendations
- Scalable analytical framework
"""
    
    with open("analysis_summary.md", "w") as f:
        f.write(summary)
    
    print("‚úì Summary report generated: analysis_summary.md")

def main():
    """Main execution function"""
    print("AADHAAR DATATHON ANALYSIS - AUTOMATED EXECUTION")
    print("="*60)
    
    # Install requirements
    if not install_requirements():
        print("‚ùå Failed to install requirements. Please install manually.")
        return
    
    # Run analysis pipeline
    results = run_analysis_pipeline()
    
    # Generate summary report
    generate_summary_report()
    
    # Final status
    success_count = sum(1 for status in results.values() if status == "SUCCESS")
    total_count = len(results)
    
    print(f"\nüéØ FINAL RESULT: {success_count}/{total_count} analyses completed successfully!")
    
    if success_count == total_count:
        print("üéâ All analyses completed successfully! Your DataThon submission is ready.")
    else:
        print("‚ö†Ô∏è  Some analyses had issues. Please check the output above.")
    
    print("\nüìÅ Files generated for your submission:")
    print("   ‚Ä¢ Python analysis scripts (data_exploration.py, aadhaar_analysis.py, advanced_insights.py)")
    print("   ‚Ä¢ Visualization images (*.png files)")
    print("   ‚Ä¢ Summary report (analysis_summary.md)")
    print("   ‚Ä¢ Requirements file (requirements.txt)")

if __name__ == "__main__":
    main()